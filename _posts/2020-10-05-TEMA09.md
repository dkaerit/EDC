--- 
layout: post
---
<div class="header">
  <div class="numbrerUnit">9</div>
  <h1>La memoria Caché</h1>
  <subtitle> </subtitle>
</div>

(30 páginas)

## 1. Principios de la caché
 - Estructura puramente hardware. Transparente para el software.
 - Entre memoria principal y CPU. Aunque el término denomina también otras estructuras entre dos niveles cualquiera de la jerarquía de memoria.
 - Busca mejorar la velocidad de acceso.
 - Menos capacidad que el nivel superior. Pero debe ser capaz de almacenar cualquier dirección de memoria.

### 1.1. Localidad de referencia
 - **Localidad espacial**: Se suele acceder de forma consecutiva a direcciones próximas de memoria. Cuando se accede a una posición de memoria, se trata de cargar el bloque de direcciones adyacente.
 - **Localidad temporal**: Se suele acceder a las mismas direcciones de forma repetitiva en el tiempo. Una vez que se trae un bloque de memoria, se trata de mantenerlo (evitar un reemplazo) en la caché el máximo tiempo posible

<blockquote>
  <b>La memoria almacena instrucciones y datos ¿Se comportan de forma similar o diferente con respecto a las diferentes dimensiones de la localidad de referencia?</b><br><br>
  Como los procesadores tienen cachés diferenciadas para instrucciones y para datos, se supone diferentes formas de funcionamiento en diferentes cachés.
  
</blockquote>

### 1.2. Funcionamiento de la caché 
#### 1.2.1. Lecturas
* Acierto (hit) tras lectura 

<center><img src="https://i.gyazo.com/e6971754ae2a929480d6363d155764aa.png"></center>
Para acceder a la caché se necesita además de indicar el valor, hay que indicar de donde proviene ese valor. La CPU manda la dirección al bus de direcciones, y la caché lee lo que le llega por el bus de direcciones.

* Fallo (miss) tras lectura

<center><img src="https://i.gyazo.com/ee5628295ceb8fbc086104154575b2cd.png"></center>
No se carga todo el bloque en la caché antes de leer el dato. Es decir si un bloque tuviera 18 palabras de memoria, no debería cargarse todo el bloque, porque tiene un costo.  

Ante un fallo ¡hay que parar el procesador! Es posible la “lectura de comienzo inmediato” (load-through)

#### 1.2.2. Métricas
 - **Frecuencia de aciertos**: Porcentaje de aciertos sobre el total de accesos
 - **Frecuencia de fallos**: Porcentaje de fallos sobre el total de accesos
 - **Tiempo de acierto**: Tiempo necesario para obtener un dato que se encuentra en caché. Tiempo de acceso + tiempo para saber si se encuentra allí
 - **Penalización por fallo**: Tiempo para traer el dato desde el nivel inferior
 - **Tiempo de fallo**: Tiempo de acierto + penalización por fallo


#### 1.2.3. Escrituras
* Escritura directa (write-through)
* Escritura retardada (write-back)

#### 1.2.4. Coherencia en sistemas multicore

## 2. Mapeado

<blockquote>
  <b>Supongamos que disponemos de un sistema de bloques de una palabra (por simplificar). Nuestra caché tiene 4 líneas y la memoria es de 8 palabras; por lo tanto, necesitaremos   3 bits para direccionar esa memoria.</b>
</blockquote>

<center><img src="https://i.gyazo.com/5e184b91df19b9034ac646464866a8c2.png"></center>

<blockquote>
  <b>Tenemos un programa que accede a las siguientes direcciones: 000, 001, 011, 001, 101, 010</b>

  1. ¿Cómo ubicamos esos bloques en la caché?
  2. Ante cada nuevo acceso, ¿cómo se sabe si la caché ya contiene ese bloque?
  3. ¿Qué hacemos cuando la caché se llene?
</blockquote>

Las técnicas de mapeado permmiten decidir en qué línea de la caché almacenar un bloque de la 
memoria. dentificar con qué bloque de la memoria principal se corresponde el contenido de una línea de la caché usando eqtiquetas.
  
Supongamos una memoria compuesta de dos conjuntos de información
  - Bloque: Infdica en que bloque de la memoria está esa direccion
  - Palabra (offset): Que palabra dentro de ese bloque es la que estoy intentando acceder

<code class="language-print">
  
  <b>Teniendo una memoria de 2^16 palabras, </b>
  <b>con bloques de 8 palabras (8 = 2^3 palabras/bloque).</b>

  ¿Cuánto ocuparía el offset? 3 bits a la palabra
  ¿Cuánto ocuparía el bloque? 16-3 = 13 bits al bloque
  
</code>
  
  
### 1.2. Mapeado directo
Dirección de memoria desde la perspectiva de la memoria principal
  
<code class="language-print">
  
  <b>Teniendo: </b><br>
  <b>Memoria de 2^m palabras. </b><br>
  <b>Caché que pueda almacenar 2^c bloques. </b> (new)<br>
  <b>Bloques de 2^b palabras</b><br><br>
  Etiqueta(m-c-b), L.Caché(c), Palabra/Offset(b)<br>
  
</code>
  
<blockquote>
  <b>Tenemos CPU con un bus de direcciones de 16 bits</b><br>
  0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15 <br><br>
  
  <b>Bloques de 16 palabras → 16 pal/blk = 2^4</b><br>
  *0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 |* pal/offset(12|13|14|15)<br><br>
  
  <b>Si el bus es de 16 bits, puedo direccionar 2^16 direcciones diferentes = 64K palabras (que no tiene por qué ser 64 Kbytes)</b><br>
  Tengo hasta el momento: 2^4 palabras/bloque y 2^16 palabras<br>
  Tengo entonces: 2^12 bloques<br><br>
  
  <b>Caché de 2K (2048 palabras = 2^11 palabras)</b><br>
  Tengo hasta el momento: 2^4 palabras/bloque y 2^11 palabras<br>
  Tengo entonces: 2^7 bloques (de los 2^12 bloques, 2^7 lo ocupa el bloque y el resto la etiqueta)<br>
  eqtiqueta(0|1|2|3|4), bloques(5|6|7|8|9|10|11), pal/offset(12|13|14|15)<br><br>
</blockquote>
  
### 1.3. Mapeado completamente asociativo
### 1.4. Mapeado asociativo por conjunto
### 1.5. Reemplazamiento
